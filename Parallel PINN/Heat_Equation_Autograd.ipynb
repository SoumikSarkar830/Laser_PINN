{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d53ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b0abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94597f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28ba5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "\n",
    "        self.layers = layers\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "\n",
    "        self.H1 = self.linears[0]\n",
    "\n",
    "        \n",
    "    'forward pass'\n",
    "    def forward(self,x,y,t):              \n",
    "        \n",
    "        # for i in range(len(self.layers)-2):\n",
    "        #     z = self.linears[i](a)\n",
    "        #     a = self.activation(z)\n",
    "\n",
    "        a = torch.cat([x,y,t], dim = 1)    #(N,3)\n",
    "\n",
    "        for i in range(len(self.layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "\n",
    "\n",
    "            \n",
    "        b = self.linears[-1](a) \n",
    "         \n",
    "        return b\n",
    "    \n",
    "    # def forward_direct(self, x):\n",
    "        \n",
    "    #     z = x.float()\n",
    "    #     H = self.linears[0].weight\n",
    "\n",
    "    #     for i in range(len(self.layers)-2):\n",
    "    #         L = self.linears[i](z)\n",
    "    #         z = self.activation(L)\n",
    "    #         G = (1-torch.square(z))*H.t() #\\sigma'(L)*H\n",
    "    #         H = torch.matmul(self.linears[i+1].weight,G.t())\n",
    "\n",
    "    #     z = self.linears[-1](z)\n",
    "         \n",
    "    #     return z,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e1e143c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = np.array([2,50,50,50,50,50,1])\n",
    "layers = np.array([3,20,20,20,20,20,1])\n",
    "# PINN = Sequentialmodel(layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79005185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting to ensure the reported peak truly reflects the training loop, rather than including earlier setup.\n",
    "\n",
    "# if device.type == 'cuda':\n",
    "#     torch.cuda.reset_peak_memory_stats(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b46e36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data\n",
    "\n",
    "x = torch.linspace(0,1,30, requires_grad = True).view(-1,1)\n",
    "y = torch.linspace(0,1,30, requires_grad = True).view(-1,1)\n",
    "t = torch.linspace(0,5,30, requires_grad = True).view(-1,1)\n",
    "\n",
    "\n",
    "if torch.is_tensor(x) != True:         \n",
    "    x = torch.from_numpy(x)  \n",
    "if torch.is_tensor(y) != True:         \n",
    "    y = torch.from_numpy(y) \n",
    "if torch.is_tensor(t) != True:         \n",
    "    t = torch.from_numpy(t) \n",
    "\n",
    "#convert to float\n",
    "x = x.float()\n",
    "y = y.float()\n",
    "t = t.float()\n",
    "\n",
    "    \n",
    "x_train,y_train,t_train = torch.meshgrid(x.squeeze(),y.squeeze(),t.squeeze(), indexing = 'xy')\n",
    "# x_train = x_train.reshape(-1,1).to(device).requires_grad_(True)     \n",
    "# y_train = y_train.reshape(-1,1).to(device).requires_grad_(True) \n",
    "# t_train = t_train.reshape(-1,1).to(device).requires_grad_(True)     \n",
    "\n",
    "x_train = x_train.reshape(-1,1).requires_grad_(True)     # 1000000 x 1\n",
    "y_train = y_train.reshape(-1,1).requires_grad_(True) \n",
    "t_train = t_train.reshape(-1,1).requires_grad_(True)     # 1000000 x 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "85a6b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_residual(x, y, t, alpha):\n",
    "    u = PINN(x,y,t)\n",
    "\n",
    "    du_dx = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]\n",
    "    du_dy = torch.autograd.grad(u, y, torch.ones_like(u), create_graph=True)[0]\n",
    "    du_dt = torch.autograd.grad(u, t, torch.ones_like(u), create_graph=True)[0]\n",
    "    du_dx_x = torch.autograd.grad(du_dx, x, torch.ones_like(du_dx), create_graph=True)[0]\n",
    "    du_dy_y = torch.autograd.grad(du_dy, y, torch.ones_like(du_dy), create_graph=True)[0]\n",
    "\n",
    "    res_pde = du_dt - alpha * (du_dx_x + du_dy_y)\n",
    "\n",
    "    return res_pde\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4203a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initial_condition(x,y):\n",
    "  u_ic = PINN(x, y, torch.zeros_like(x))\n",
    "  res_ic = u_ic - ((torch.sin(np.pi * x))*(torch.sin(np.pi * y)))\n",
    "  return res_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "887efbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_condition(x,y,t):\n",
    "    u_left = PINN(torch.full_like(t, 0),y, t)\n",
    "    u_right = PINN(torch.full_like(t, 1),y, t)\n",
    "\n",
    "    u_bottom = PINN(x,torch.full_like(t, 0), t)\n",
    "    u_top = PINN(x,torch.full_like(t, 1), t)\n",
    "\n",
    "    res_left = u_left - torch.zeros_like(t)\n",
    "    res_right = u_right - torch.zeros_like(t)\n",
    "    res_bottom = u_bottom - torch.zeros_like(t)\n",
    "    res_top = u_top - torch.zeros_like(t)\n",
    "\n",
    "    return res_left, res_right,res_bottom, res_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "02724e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses():\n",
    "   res_pde = pde_residual(x_train, y_train, t_train, alpha = 0.01) \n",
    "   res_ic = initial_condition(x_train,y_train)\n",
    "   res_left, res_right,res_bottom, res_top = boundary_condition(x_train, y_train, t_train)\n",
    "\n",
    "   loss_pde = torch.mean(res_pde**2)\n",
    "   loss_ic = torch.mean(res_ic**2)\n",
    "   loss_bc = torch.mean(res_left**2) + torch.mean(res_right**2) + torch.mean(res_bottom**2) + torch.mean(res_top**2)\n",
    "\n",
    "   total_loss = loss_pde + loss_ic + loss_bc\n",
    "\n",
    "   return total_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(PINN.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65394b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of epochs\n",
    "\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# num_epochs = 10000\n",
    "\n",
    "\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     total_loss = compute_losses()\n",
    "\n",
    "    \n",
    "#     total_loss.backward()\n",
    "\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if (epoch) % 200 == 0:\n",
    "#      print(f'Epoch {epoch}, Loss: {total_loss.item()}')\n",
    "\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# print(f'Total Training Time: {(end_time - start_time): .4f}seconds')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28d6fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# PINN = Sequentialmodel(layers).to(device)\n",
    "PINN = Sequentialmodel(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if device.type == 'cuda':\n",
    "#     torch.cuda.reset_peak_memory_stats(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(PINN.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f591103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Threshold loss as the stopping criteria\n",
    "\n",
    "# max_epochs = 15000\n",
    "# threshold = 0.002\n",
    "\n",
    "\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# ep = 0\n",
    "# while ep < max_epochs:\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     total_loss = compute_losses()\n",
    "\n",
    "    \n",
    "#     total_loss.backward()\n",
    "\n",
    "#     optimizer.step()\n",
    "\n",
    "\n",
    "#     if total_loss.item() < threshold:\n",
    "#         print(f\"Reached threshold loss {threshold} at epoch {ep}\")\n",
    "#         break\n",
    "\n",
    "#     if (ep) % 200 == 0:\n",
    "#      print(f'Epoch {ep}, Loss: {total_loss.item()}')\n",
    "\n",
    "#     ep += 1\n",
    "\n",
    "\n",
    "# print(f\"Training stopped at epoch {ep}, total time {time.time() - start_time:.2f} s\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d3cfba6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer 0, Loss: 1.6748554706573486\n",
      "Reached threshold loss 0.002 at outer step 15\n",
      "Training stopped at outer step 15, total time 38.77 s\n"
     ]
    }
   ],
   "source": [
    "# Using LBFGS\n",
    "\n",
    "optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05,max_iter=20,history_size=50,tolerance_grad=1e-9,tolerance_change=1e-9,line_search_fn='strong_wolfe')\n",
    "\n",
    "max_outer_steps = 15000\n",
    "threshold = 0.002\n",
    "\n",
    "start_time = time.time()\n",
    "ep = 0\n",
    "\n",
    "\n",
    "def closure():\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    total_loss = compute_losses()\n",
    "    total_loss.backward()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "while ep < max_outer_steps:\n",
    "\n",
    "    total_loss = optimizer.step(closure)\n",
    "\n",
    "    if total_loss.item() < threshold:\n",
    "        print(f\"Reached threshold loss {threshold} at outer step {ep}\")\n",
    "        break\n",
    "\n",
    "    if ep % 200 == 0:\n",
    "        print(f'Outer {ep}, Loss: {total_loss.item()}')\n",
    "\n",
    "    ep += 1\n",
    "\n",
    "print(f\"Training stopped at outer step {ep}, total time {time.time() - start_time:.2f} s\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "172793fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak GPU Memory Usage:  32471.80 MB\n"
     ]
    }
   ],
   "source": [
    "# Memory usage after training\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    peak_mem = torch.cuda.max_memory_allocated(device)\n",
    "    print(f'Peak GPU Memory Usage: {peak_mem / 1e6: .2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663e191e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[130, 130]' is invalid for input of size 2197000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m t_test \u001b[38;5;241m=\u001b[39m t_test\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     23\u001b[0m u_test \u001b[38;5;241m=\u001b[39m u_test\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m---> 25\u001b[0m x_test \u001b[38;5;241m=\u001b[39m \u001b[43mx_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m130\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m130\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m y_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m130\u001b[39m,\u001b[38;5;241m130\u001b[39m)\n\u001b[1;32m     27\u001b[0m t_test \u001b[38;5;241m=\u001b[39m t_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m130\u001b[39m,\u001b[38;5;241m130\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[130, 130]' is invalid for input of size 2197000"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "x_test = torch.linspace(-1,1,130, requires_grad = False).to(device).view(-1,1)\n",
    "y_test = torch.linspace(-1,1,130, requires_grad = False).to(device).view(-1,1)\n",
    "t_test = torch.linspace(0,1,130, requires_grad = False).to(device).view(-1,1)\n",
    "\n",
    "x_test,y_test,t_test = torch.meshgrid(x_test.squeeze(),y_test.squeeze(),t_test.squeeze(), indexing = 'xy')\n",
    "\n",
    "x_test = x_test.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "t_test = t_test.reshape(-1,1)\n",
    "\n",
    "PINN.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  u_test = PINN(x_test, y_test, t_test)\n",
    "\n",
    "# Reshape the predicted u values for contour plotting\n",
    "x_test = x_test.cpu()\n",
    "y_test = y_test.cpu()\n",
    "t_test = t_test.cpu()\n",
    "\n",
    "u_test = u_test.cpu()\n",
    "\n",
    "x_test = x_test.reshape(130,130,130)\n",
    "y_test = y_test.reshape(130,130,130)\n",
    "t_test = t_test.reshape(130,130,130)\n",
    "\n",
    "u_test = u_test.reshape(130,130,130)\n",
    "\n",
    "# Plot the PINN solution as a contour plot\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.contourf(x_test, y_test, t_test, u_test, cmap='viridis')\n",
    "plt.colorbar(label='u')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('PINN Solution')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
